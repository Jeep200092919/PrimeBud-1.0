import streamlit as st
import requests
import json
import concurrent.futures

# ==========================================
# CONFIGURAÃ‡Ã•ES GERAIS
# ==========================================
st.set_page_config(page_title="PrimeBud Turbo 1.0", page_icon="ğŸ¤–", layout="wide")

OLLAMA_URL = "http://localhost:11434/api/chat"
GITHUB_URL = "https://github.com/Jeep200092919/PrimeBud-Turbo-1.0"

# ==========================================
# MODELOS DISPONÃVEIS
# ==========================================
MODEL_IDS = {
    "LLaMA 3": "llama3",
    "CodeGemma 7B": "codegemma:7b",
    "Phi-3": "phi3",
}

# ==========================================
# BASE DE USUÃRIOS
# ==========================================
if "usuarios" not in st.session_state:
    st.session_state.usuarios = {"teste": {"senha": "0000", "plano": "Free"}}

# ==========================================
# DESCRIÃ‡ÃƒO DOS MODOS
# ==========================================
MODOS_DESC = {
    "âš¡ Flash": "Respostas instantÃ¢neas (LLaMA 3 turbo).",
    "ğŸ”µ Normal": "Respostas equilibradas e naturais (LLaMA 3 turbo).",
    "ğŸƒ EconÃ´mico": "Respostas curtas e otimizadas (LLaMA 3 turbo).",
    "ğŸ’¬ Mini": "Conversas leves e diretas (LLaMA 3 turbo).",
    "ğŸ’ Pro (Beta)": "CÃ³digo + explicaÃ§Ã£o curta (CodeGemma 7B turbo).",
    "â˜„ï¸ Ultra (Beta)": "Pipeline turbo (LLaMA 3 â†’ CodeGemma 7B â†’ Phi-3).",
    "âœï¸ Escritor": "Textos criativos de 5â€“10 linhas (Phi-3 turbo).",
    "ğŸ« Escola": "Ajuda escolar (Phi-3 + LLaMA 3 turbo).",
    "ğŸ‘¨â€ğŸ« Professor": "DidÃ¡tico e estruturado â€” LLaMA 3 com clareza e paciÃªncia.",
    "ğŸ¨ Designer": "Criativo e visual â€” LLaMA 3 rÃ¡pido e imaginativo.",
    "ğŸ’» Codificador": "TÃ©cnico e direto â€” LLaMA 3 preciso e limpo.",
    "ğŸ§© EstratÃ©gias": "AnalÃ­tico e estruturado â€” LLaMA 3 equilibrado e estratÃ©gico.",
}

# ==========================================
# LIMITES DE MODELOS POR MODO
# ==========================================
MODE_LIMITS = {
    "âš¡ Flash": ["LLaMA 3"],
    "ğŸ”µ Normal": ["LLaMA 3"],
    "ğŸƒ EconÃ´mico": ["LLaMA 3"],
    "ğŸ’¬ Mini": ["LLaMA 3"],
    "ğŸ’ Pro (Beta)": ["CodeGemma 7B"],
    "â˜„ï¸ Ultra (Beta)": ["PIPELINE"],
    "âœï¸ Escritor": ["Phi-3"],
    "ğŸ« Escola": ["DUO"],
    "ğŸ‘¨â€ğŸ« Professor": ["WORK"],
    "ğŸ¨ Designer": ["WORK"],
    "ğŸ’» Codificador": ["WORK"],
    "ğŸ§© EstratÃ©gias": ["WORK"],
}

# ==========================================
# FUNÃ‡ÃƒO DE CHAT OLLAMA (SEM TIMEOUT)
# ==========================================
def chat_ollama(model: str, prompt: str, options: dict | None = None) -> str:
    payload = {
        "model": model,
        "stream": False,
        "messages": [
            {"role": "system", "content": "VocÃª Ã© o PrimeBud. Seja claro, rÃ¡pido e Ãºtil."},
            {"role": "user", "content": prompt}
        ]
    }
    if options:
        payload["options"] = options

    r = requests.post(OLLAMA_URL, json=payload)
    try:
        data = r.json()
    except json.JSONDecodeError:
        data = json.loads(r.text.strip().split("\n")[0])
    return data["message"]["content"]

# ==========================================
# PIPELINES ESPECIAIS (TURBO)
# ==========================================
def gerar_resposta_ultra(msg: str) -> str:
    with concurrent.futures.ThreadPoolExecutor() as ex:
        f1 = ex.submit(chat_ollama, MODEL_IDS["LLaMA 3"], f"Resuma o problema em 2 linhas: {msg}", {"num_predict": 200})
        llama = f1.result()
        f2 = ex.submit(chat_ollama, MODEL_IDS["CodeGemma 7B"], f"Crie cÃ³digo funcional baseado em: {llama}", {"num_predict": 250})
        code = f2.result()
        phi = chat_ollama(MODEL_IDS["Phi-3"], f"Explique o cÃ³digo abaixo em atÃ© 6 linhas:\n{code}", {"num_predict": 250})
    return phi

def gerar_resposta_duo_escola(msg: str) -> str:
    with concurrent.futures.ThreadPoolExecutor() as ex:
        f1 = ex.submit(chat_ollama, MODEL_IDS["Phi-3"], f"Explique didaticamente: {msg}", {"num_predict": 250})
        f2 = ex.submit(chat_ollama, MODEL_IDS["LLaMA 3"], f"DÃª 1 exemplo prÃ¡tico: {msg}", {"num_predict": 250})
        r1 = f1.result()
        r2 = f2.result()
    return f"{r1}\n\nğŸ“˜ Exemplo:\n{r2}"

# ==========================================
# MODOS TRABALHO (APENAS LLaMA 3 TURBO)
# ==========================================
def gerar_resposta_work(modo: str, msg: str) -> str:
    configs = {
        "ğŸ‘¨â€ğŸ« Professor": {
            "prompt": (
                f"VocÃª Ã© o PrimeBud PROFESSOR: didÃ¡tico e paciente.\n"
                f"Explique em passos curtos, com exemplos claros e diretos.\nTema: {msg}"
            ),
            "options": {"temperature": 0.4, "num_predict": 450, "top_p": 0.9}
        },
        "ğŸ¨ Designer": {
            "prompt": (
                f"VocÃª Ã© o PrimeBud DESIGNER: criativo e visual.\n"
                f"Gere ideias, esquemas visuais, estilos, cores e tipografia.\nBriefing: {msg}"
            ),
            "options": {"temperature": 0.95, "num_predict": 350, "top_p": 0.95}
        },
        "ğŸ’» Codificador": {
            "prompt": (
                f"VocÃª Ã© o PrimeBud CODIFICADOR: tÃ©cnico e rÃ¡pido.\n"
                f"Crie cÃ³digo funcional e explique em poucas linhas.\nTarefa: {msg}"
            ),
            "options": {"temperature": 0.2, "num_predict": 400, "top_p": 0.9}
        },
        "ğŸ§© EstratÃ©gias": {
            "prompt": (
                f"VocÃª Ã© o PrimeBud ESTRATÃ‰GICO: analÃ­tico e equilibrado.\n"
                f"Monte um plano prÃ¡tico com metas, aÃ§Ãµes e riscos claros.\nDesafio: {msg}"
            ),
            "options": {"temperature": 0.6, "num_predict": 420, "top_p": 0.9}
        },
    }
    cfg = configs.get(modo, configs["ğŸ§© EstratÃ©gias"])
    return chat_ollama(MODEL_IDS["LLaMA 3"], cfg["prompt"], cfg["options"])

# ==========================================
# GERADOR PADRÃƒO (TURBO)
# ==========================================
def gerar_resposta(modelo_display: str | None, modo: str, msg: str) -> str:
    if modo == "â˜„ï¸ Ultra (Beta)": return gerar_resposta_ultra(msg)
    if modo == "ğŸ« Escola": return gerar_resposta_duo_escola(msg)
    if MODE_LIMITS.get(modo) == ["WORK"]: return gerar_resposta_work(modo, msg)

    prompt = f"{msg}"
    if modelo_display is None: modelo_display = "LLaMA 3"
    model_id = MODEL_IDS[modelo_display]
    return chat_ollama(model_id, prompt, {"num_predict": 400})

# ==========================================
# LOGIN E SISTEMA DE USUÃRIOS
# ==========================================
if "usuario" not in st.session_state: st.session_state.usuario = None
if "plano" not in st.session_state: st.session_state.plano = None

if st.session_state.usuario is None:
    st.title("ğŸ¤– PrimeBud Turbo 1.0 â€” Login")
    st.link_button("ğŸŒ Ver no GitHub", GITHUB_URL)
    aba = st.tabs(["Entrar", "Criar conta", "Convidado (Ultra)"])

    with aba[0]:
        u = st.text_input("UsuÃ¡rio")
        p = st.text_input("Senha", type="password")
        if st.button("Entrar"):
            db = st.session_state.usuarios
            if u in db and db[u]["senha"] == p:
                st.session_state.usuario = u
                st.session_state.plano = db[u]["plano"]
                st.rerun()
            else:
                st.error("UsuÃ¡rio ou senha incorretos.")

    with aba[1]:
        novo_u = st.text_input("Novo usuÃ¡rio")
        nova_s = st.text_input("Nova senha", type="password")
        plano_escolhido = st.selectbox("Plano inicial", ["Free", "Pro", "Ultra", "Trabalho", "Professor"])
        if st.button("Criar conta"):
            db = st.session_state.usuarios
            db[novo_u] = {"senha": nova_s, "plano": plano_escolhido}
            st.session_state.usuario = novo_u
            st.session_state.plano = plano_escolhido
            st.rerun()

    with aba[2]:
        if st.button("Entrar como convidado (Ultra)"):
            st.session_state.usuario = "Convidado"
            st.session_state.plano = "Ultra"
            st.rerun()
    st.stop()

usuario = st.session_state.usuario
plano = st.session_state.plano

# ==========================================
# MULTICHATS E INTERFACE
# ==========================================
if "chats" not in st.session_state: st.session_state.chats = []
if "chat_atual" not in st.session_state:
    st.session_state.chat_atual = 0
    st.session_state.chats.append({"nome": "Chat 1", "historico": []})

def novo_chat():
    n = len(st.session_state.chats) + 1
    st.session_state.chats.append({"nome": f"Chat {n}", "historico": []})
    st.session_state.chat_atual = len(st.session_state.chats) - 1
    st.rerun()

with st.sidebar:
    st.title(f"ğŸ¤– PrimeBud â€” {usuario}")
    if st.button("â• Novo chat"): novo_chat()
    chats = [c["nome"] for c in st.session_state.chats]
    idx = st.radio("Seus chats:", list(range(len(chats))), format_func=lambda i: chats[i])
    st.session_state.chat_atual = idx

    modos_por_plano = {
        "Free": ["ğŸ’¬ Mini", "ğŸƒ EconÃ´mico", "âœï¸ Escritor", "ğŸ« Escola"],
        "Pro": ["âš¡ Flash", "ğŸ”µ Normal", "ğŸ’ Pro (Beta)", "ğŸƒ EconÃ´mico", "âœï¸ Escritor", "ğŸ« Escola"],
        "Ultra": ["âš¡ Flash", "ğŸ”µ Normal", "ğŸ’ Pro (Beta)", "ğŸƒ EconÃ´mico", "ğŸ’¬ Mini",
                  "â˜„ï¸ Ultra (Beta)", "âœï¸ Escritor", "ğŸ« Escola",
                  "ğŸ‘¨â€ğŸ« Professor", "ğŸ¨ Designer", "ğŸ’» Codificador", "ğŸ§© EstratÃ©gias"],
        "Trabalho": ["ğŸ‘¨â€ğŸ« Professor", "ğŸ¨ Designer", "ğŸ’» Codificador", "ğŸ§© EstratÃ©gias",
                     "âœï¸ Escritor", "ğŸ« Escola"],
        "Professor": ["ğŸ‘¨â€ğŸ« Professor", "ğŸ« Escola", "âœï¸ Escritor"],
    }

    lista_modos = modos_por_plano.get(plano, modos_por_plano["Ultra"])
    modo = st.radio("Modo:", lista_modos)
    st.caption(MODOS_DESC.get(modo, "Modo customizado."))

# ==========================================
# ÃREA PRINCIPAL DE CHAT
# ==========================================
chat = st.session_state.chats[st.session_state.chat_atual]
st.markdown(f"### ğŸ’¬ {chat['nome']}")

for m in chat["historico"]:
    who = "VocÃª" if m["autor"] == "user" else "PrimeBud"
    color = "#2b313e" if m["autor"] == "user" else "#ececf1"
    text_color = "#fff" if m["autor"] == "user" else "#000"
    st.markdown(f"<div style='background:{color};color:{text_color};padding:10px;border-radius:10px;margin:6px 0;'><b>{who}:</b> {m['texto']}</div>", unsafe_allow_html=True)

msg = st.chat_input("Envie uma mensagemâ€¦")
if msg:
    chat["historico"].append({"autor": "user", "texto": msg})
    with st.spinner("Turbo..."):
        resposta = gerar_resposta(None, modo, msg)
    chat["historico"].append({"autor": "bot", "texto": resposta})
    st.rerun()
